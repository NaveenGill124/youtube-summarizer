# ğŸ—ï¸ Project Architecture â€” YouTube Summarizer (Chrome Extension + FastAPI RAG Backend)

This document explains the complete architecture of the YouTube Summarizer project, including extension flow, backend RAG pipeline, data storage, and execution logic.

---

# ğŸ“‚ Folder Structure
```
youtube-summarizer/
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ main.py # FastAPI application (RAG pipeline)
â”‚ â”œâ”€â”€ requirements.txt # Python dependencies
â”‚ â”œâ”€â”€ .env # Environment variables (ignored)
â”‚ â””â”€â”€ vectorstores/ # FAISS indexes (gitignored)
â”‚ â””â”€â”€ {video_id}/
â”‚ â”œâ”€â”€ index.faiss # Vector embeddings
â”‚ â”œâ”€â”€ chunks.json # Preprocessed text chunks
â”‚ â”œâ”€â”€ metadata.json # Timestamp metadata
â”‚ â””â”€â”€ transcript.json # Raw transcript
â”‚
â”œâ”€â”€ manifest.json # Chrome extension config
â”œâ”€â”€ content_script.js # In-video overlay (Shadow DOM UI)
â”œâ”€â”€ popup.html # Extension popup UI
â”œâ”€â”€ popup.js # Logic for popup UI
â”œâ”€â”€ icons/ # All extension icons (16, 48, 128)
â”‚
â”œâ”€â”€ README.md # Main Project Documentation
â””â”€â”€ ARCHITECTURE.md # This file


```

---

# âš™ï¸ System Architecture Overview

The system consists of:

### **1ï¸âƒ£ Chrome Extension**
- Detects YouTube video ID
- Injects floating AI overlay using Shadow DOM
- Sends queries to backend over REST
- Displays summary, QnA, key points, timestamps

### **2ï¸âƒ£ FastAPI Backend**
Implements a complete RAG pipeline:
- Extracts YouTube transcript (3 fallback methods)
- Splits transcript into chunks (time-aware)
- Generates embeddings using OpenAI
- Stores vectors in FAISS index
- Queries vectors based on user questions
- Produces answer using GPT-4o-mini

### **3ï¸âƒ£ Vector Store (FAISS)**
Stores:
- FAISS index
- chunk text
- timestamp metadata
- raw transcript

---

# ğŸ”„ Data Flow Diagram

               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚        Chrome Extension   â”‚
               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
               â”‚ â”‚ Popup UI     â”‚          â”‚
               â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
               â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
               â”‚ â”‚ Overlay UI   â”‚â”€â”€Renderâ†’ Shadow DOM
               â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚  Response
                         â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚    FastAPI Backend â”‚
                â”‚                    â”‚
                â”‚ Transcript Extract â”‚â† Fetch â† YouTube
                â”‚ Chunking           â”‚
                â”‚ Embeddings         â”‚â†’ OpenAI text-embedding-3-small
                â”‚ Vector Store (FAISS) 
                â”‚ RAG Query Handler  â”‚â†’ GPT-4o-mini (LLM Answer)
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ Store
                   â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                   â”‚ Vector DB â”‚
                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



---

# ğŸ” Backend RAG Pipeline Details

### **1. Transcript Extraction**
Backend uses 3 fallback methods:

1. YouTube timedtext API  
2. HTML caption scraping  
3. `yt-dlp` auto extractor (**99% success rate**)  

Transcript saved as:  
`vectorstores/{video_id}/transcript.json`

---

### **2. Chunking (Time-Based)**
Each transcript is split:

- Chunk length: **~120 seconds**
- Overlap: **20 seconds**
- Metadata stored with timestamps

This ensures answer accuracy and relevance.

---

### **3. Embedding Generation**
Uses:

text-embedding-3-small


Embeddings stored in FAISS index:
`index.faiss`

---

### **4. Vector Search (FAISS)**
On each user question:
- Query embedded
- Top-k vectors retrieved
- Chunk text injected into LLM prompt

---

### **5. LLM Answer Generation**
Uses:
gpt-4o-mini


LLM generates:
- Summary  
- QnA  
- Key Insights  
- Timestamped references  

---

# ğŸ¯ Key Technologies
- **FastAPI** â€” backend server
- **FAISS** â€” vector similarity search
- **yt-dlp** â€” robust transcript extraction
- **OpenAI models** â€” embeddings + generation
- **Chrome Extensions API**
- **Shadow DOM** â€” isolation for UI & CSS

---

# ğŸ“ Notes
- The extension works entirely locally using the local backend
- Backend must be running for extension to function

---

# âœ” Architecture is final, stable & production-ready.
